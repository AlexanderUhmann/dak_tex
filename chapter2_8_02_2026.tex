\chapter{Алгоритмы машинного и глубокого обучения в задаче о кредитном скоринге}
       	
	\section{Предобработка данных кредитной истории клиентов банка}
	В данной работе используются обезличенные данные АО «Альфа-Банка»\footnote{\cite{Alfabank} (дата обращения 25.11.2025)}. Данные состоят из 12 файлов (\texttt{train\_data\_0.pq - train\_data\_11.pq}), содержащих информацию о платежах клиентов банка. В каждом из 12 файлов содержится информация о 250 000 клиентах. При этом один клиент может иметь несколько кредитов, и каждому такому клиенту соответствует персональный \texttt{id} (идентификационный номер). Отдельно имеется файл \texttt{train\_target.csv}, который состоит из 3 млн строк, и каждая строка соответствует клиенту с меткой (флагом) равной 0 (отсутствие дефолта) или 1 (наличие дефолта). 
	Задача предобработки данных состоит в структурировании исходной информации, т.е. формирование единого датасета, выделение важных признаков (колонок), выявление аномальных клиентов (определение аномальности  будет приведено ниже), визуализация данных и тестирование моделей МО и ГО на этих данных. Программный код формирования единого датасета реализован в листинге \ref{train_data_csv_all_py} (см. приложение 1). 
{\co Пояснение к листингу \ref{train_data_csv_all_py}:} 
	\begin{enumerate}
	       \item Строки 1 -- 3. Импортируются необходимые библиотеки: \texttt{pandas} -- для работы с табличными данными, \texttt{os} -- для работы с файловой системой и \texttt{pyarrow.parquet} -- для чтения файлов формата \texttt{.parquet}.
               \item Строка 5. Задается путь \texttt{path = "train\_data"} к папке,
в которой находятся исходные файлы формата \texttt{.pq}.
               \item Строки 6 -- 13. Запускается цикл \texttt{for}, который перебирает все файлы в папке \texttt{train\_data}. Формируется имя поочередного файла \texttt{train\_data\_i.pq}, создается объект \texttt{ParquetDataset} для текущего файла, из которого данные считываются в \texttt{DataFrame (df)}. Затем выполняется агрегация данных по признаку \texttt{id}, вычисляются средние значения признаков, после чего данные сохраняются в соответствующий \texttt{csv} -- файл в папку \texttt{train\_data\_csv\_all}.
               \item Строка 14. Выводится список файлов каталога \texttt{train\_data} для проверки корректности формирования файлов.
               \item Строки 16 -- 21. Задается путь к папке с полученными \texttt{csv}-файлами \texttt{train\_data\_csv\_all}. Создается пустой список \texttt{frames} для последующего хранения отдельных \texttt{DataFrame}. Затем запускается цикл по файлам в папке \texttt{train\_data\_csv\_all}, который последовательно перебирает все файлы в формате \texttt{.csv}. Результат сохраняется в \texttt{DataFrame (df)} и добавляется в список \texttt{frames}. 
               \item Строки 23 -- 26. Все элементы списка \texttt{frames} объединяются в единый \texttt{DataFrame result} с помощью функции \texttt{pd.concat}. Полученный датасет сохраняется в файл \texttt{1\_data\_csv\_all.csv}, после чего заново считывается в переменную \texttt{df\_all} для последующего анализа.
        \end{enumerate}
        
        После преобразования получился следующий датасет. В таблице \ref{df_fragment} приводится фрагмент датасета:
        
\begin{table}[H]
\centering
\caption{Фрагмент преобразованного датасета, содержащий первых 5 клиентов}
\label{df_fragment}
\begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  \rowcolor[gray]{.9}
   id & enc\_paym\_0 & enc\_paym\_1 & enc\_paym\_2 & enc\_paym\_3 & enc\_paym\_4 & flag \\
  \hline
  1750000 & 0.17 & 0.17 & 0.17 & 0.33 & 0.67 & 0 \\ \hline
  1750001 & 0.00 & 0.75 & 0.75 & 0.75 & 0.75 & 0 \\ \hline
  1750002 & 0.39 & 0.33 & 0.72 & 0.67 & 1.17 & 0 \\ \hline
  1750003 & 0.18 & 0.23 & 0.41 & 0.50 & 0.55 & 0 \\ \hline
  1750004 & 0.60 & 0.60 & 0.60 & 0.60 & 1.20 & 0 \\ \hline
\end{tabular}

\vspace{3mm} 

\begin{minipage}{0.98\textwidth}
  \fontsize{9}{11}\selectfont
  \justifying
Примечание: id -- идентификатор заявки; \texttt{enc\_paym\_0}, \dots, \texttt{enc\_paym\_n} -- статусы ежемесячных платежей за последние $n$ месяцев; flag -- статус кредита (0=кредит полностью оплачен). Полный датасет состоит из 61 признака, включая дополнительные характеристики по кредитам.
\end{minipage}
\end{table}
        
{\co Пояснение к агрегированию клиентов в листинге \ref{train_data_csv_all_py}:}    
     
        Агрегация клиентов по идентификатору \texttt{id} в строке 11 необходима для определения итоговой метки (флага) каждого клиента, поскольку одному заемщику может соответствовать несколько кредитных договоров. Задача состоит в присвоении каждому кредиту одного заемщика единую итоговую. метку. В данном исследовании в качестве общего значения для всех кредитов используется среднее исходных значений. Для понимания идеи приводится следующий пример в виде таблицы  \ref{table_1_1:dfgr} :
        
\begin{center}
  \begin{longtable}{|c|c|c|c|c|c|c|c|c|}
   \caption{Дисциплина оплаты кредитов клиента (id = 1)}
    \label{table_1_1:dfgr} \\
    \hline
    \rowcolor[gray]{.9}
     id  &  N  &  M1 &  M2 & M3 & M4 & M5 & M6 & flag   \\
     \hline
     1   &  1   &  1   &  0    &  1   &  1   &  0   &  1  &\multirow{3}{*}{0}\\
     \hhline{|--------~|} % горизонтальная линия с 1-ой строки по по 8-ую строку
     1   &  2   &  0   &  \cellcolor[gray]{.9}\textbf{1}  &  0   &  1   &  1   &  2  &\\
     \cline{1-8}
     1   &  3   &  1   &  2    &  0   &  0   &  3   &  2  &\\
     \cline{1-9} 
     & &\multicolumn{6}{|c|}{ Среднее значение } & \\
     \hline
     1  &   &  0.67  &  1  &  0.33  &  1  &  1.33  &  1.67  & 0 \\
     \hline
\end{longtable}
    
\begin{minipage}{\textwidth}
   \fontsize{9}{11}\selectfont
   \justifying
   Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. – URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
\end{minipage}
\end{center}
        
        В данной таблице признаки означают следующее:
\begin{enumerate}
   \item \texttt{id} -- идентификационный номер клиента;
   \item \texttt{N} -- номер кредита;
   \item \texttt{M1,...,M6} -- статусы погашения в течение 6 месяцев (0=платеж вовремя оплачен, 1=задержка платежа на 1 день, 2=задержка платежа на 2 дня, 3=задержка платежа на 3 дня);
    \item \texttt{flag} -- статус кредита (0=кредит полностью оплачен).
\end{enumerate}
        
        В таблице \ref{table_1_1:dfgr} на пересечении N=2 (второго кредита) и M2 (платеж во втором месяце) выделена цифра 1, означающая, что платеж по второму кредиту во втором месяце был оплачен с опозданием на 1 день.
        
        Таким образом, данные трех строк, соответствующих трем кредитам клиента, в таблице \ref{table_1_1:dfgr} были усреднены и преобразованы в одну строку, которая содержит агрегированную информацию по клиенту с \texttt{id = 1}. В целом агрегировать клиентов можно не только по среднему значению, но и по моде или медиане. Однако в данной работе выбрано среднее значение, поскольку оно обладает важными статистическими свойствами, такими как несмещенность и состоятельность. После группирования данных был сформирован новый датасет, состоящий из 3 млн клиентов, каждому из которых соответствует одна итоговая метка. Получившийся датасет содержит 61 признак, из которых далее необходимо отобрать наиболее информативные, т.е. такие признаки, существенно влияющие на точность алгоритмов МО и ГО.
        
        
\subsection{Метод главных компонент}

Метод главных компонент (англ. $principal\ component\ analysis$, $PCA$) -- метод сокращения размерности данных, позволяющий уменьшать количество признаков с сохранением максимального объема исходной информации\footnote{\cite{PCA} (дата обращения: 25.11.2025).}, на которых обучаются модели МО и ГО.

Как уже было отмечено выше сформированный датасет содержит 61 признак (столбец). Задача состоит в том, чтобы найти такие признаки, на которые модели МО и ГО показывали приемлемую точность. Следует отметить, что редукция признаков может уменьшить точность алгоритмов, поэтому необходимо внимательно следить за процессом сокращения данных. В качестве тестового алгоритма был выбран алгоритм $Random\ Forest$ (случайный лес), поскольку в статье С.В. Смирнова \footnote{ \cite{Smirnov} (дата обращения: 25.11.2025).}
был проведен анализ предпочтения исследователей к алгоритмам МО, показавший, что наиболее популярным является случайный лес.

Из преобразованного датасета изначально выбираются только некатегориальные признаки и формируется новый датасет, содержащий 41 признак. Ниже приводится смысл этих признаков:

\begin{enumerate}
    \item \texttt{pre\_pterm} -- плановое количество дней с даты открытия кредита до даты его закрытия;
    \item \texttt{pre\_fterm} -- фактическое количество дней с даты открытия кредита до даты его закрытия;
    \item \texttt{pre\_loans\_next\_pay\_summ} -- сумма следующего платежа по кредиту;
    \item \texttt{pre\_loans\_outstanding} -- оставшаяся невыплаченная сумма кредита;
    \item \texttt{pre\_loans\_total\_overdue} -- текущая просроченная задолженность по кредиту;
    \item \texttt{pre\_loans\_max\_overdue\_sum} -- максимальная просроченная задолженность по кредиту за весь срок;
    \item \texttt{pre\_loans\_credit\_cost\_rate} -- полная стоимость кредита;
    \item \texttt{is\_zero\_loans5} -- флаг: нет просрочек до 5 дней;
    \item \texttt{is\_zero\_loans530} -- флаг: нет просрочек от 5 до 30 дней;
    \item \texttt{is\_zero\_loans3060} -- флаг: нет просрочек от 30 до 60 дней;
    \item \texttt{is\_zero\_loans6090} -- флаг: нет просрочек от 60 до 90 дней;
    \item \texttt{is\_zero\_loans90} -- флаг: нет просрочек более чем на 90 дней;
    \item \texttt{pre\_util} -- отношение оставшейся невыплаченной суммы кредита к кредитному лимиту;
    \item \texttt{pre\_maxover2limit} -- отношение максимальной просроченной задолженности к кредитному лимиту;
    \item \texttt{is\_zero\_util} – флаг: отношение оставшейся невыплаченной суммы кредита к кредитному лимиту равно 0;
    \item \texttt{is\_zero\_over2limit} -- флаг: отношение текущей просроченной задолженности к кредитному лимиту равно 0;
   \item \texttt{enc\_paym\_0}, \dots, \texttt{enc\_paym\_n} -- статусы ежемесячных платежей за последние $n$ месяцев.
\end{enumerate}

Далее из этих 41 признака необходимо выбрать только такие, которые вносят наибольший вклад в информативность данных. В листинге  \ref{feat_41_py} (см. Приложение 1) реализован метод главных компонент. На таком наборе данных алгоритм показывает следующие метрики (см. Таблицу \ref{metrics_41}):

\begin{center}
  \begin{longtable}{|c|c|c|c|c|c|c|}
    \caption{Метрики точности на 41 признаке }
    \label{metrics_41} \\
    \hline
    \multicolumn{7}{|c|}{Алгоритм -- Случайный лес}\\
    \hline
    \rowcolor[gray]{.9}
    \specialcell{Flag\\метка} &
    \specialcell{Precision\\точность} &
    \specialcell{Recall\\полнота} &
    \specialcell{f1--score\\f1--мера} &
    \specialcell{Accuracy\\точность}  &
    ROC--AUC &
    Количество    \\
    \hline
    \multicolumn{7}{|c|}{Тренировочная выборка}\\
    \hline
    0 & 1.00 & 0.97 & 0.98 &
    \multirow{2}{*}{0.97} &   
    \multirow{2}{*}{0.67} &  
    724650 \\                    
    \cline{1-4} \cline{7-7}
    1 & 0.00 & 0.00 & 0.00 &  
      &      & 25350 \\       
    \hline
    \multicolumn{7}{|c|}{Тестовая выборка} \\
    \hline
    0 & 1.00 & 0.97 & 0.98 &
    \multirow{2}{*}{0.97} &
    \multirow{2}{*}{0.50} &
    241508 \\
    \cline{1-4} \cline{7-7}
    1 & 0.00 & 0.00 & 0.00 & & & 8493 \\
    \hline
  \end{longtable}
  \begin{minipage}{\textwidth}
    \fontsize{9}{11}\selectfont
    \justifying
    Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
  \end{minipage}
\end{center}

Были получены результаты $PCA$:
\begin{equation}
%\setlength{\arraycolsep}{1.2ex} % компактные столбцы
\label{pca_lambda41}
\begin{alignedat}{5} % 5 лямбда в строке
\lambda_{1}^{(p)}  &= 22.3, & \lambda_{2}^{(p)}  &= 20.3, & \lambda_{3}^{(p)}  &= 17.6, & \lambda_{4}^{(p)}  &= 10.8, & \lambda_{5}^{(p)}  &=  9.5,\\
\lambda_{6}^{(p)}  &=  7.6, & \lambda_{7}^{(p)}  &=  4.2, & \lambda_{8}^{(p)}  &=  1.7, & \lambda_{9}^{(p)}  &=  1.5, & \lambda_{10}^{(p)} &=  0.8,\\
\lambda_{11}^{(p)} &= 0.6, & \lambda_{12}^{(p)} &= 0.5, & \lambda_{13}^{(p)} &= 0.4, & \lambda_{14}^{(p)} &= 0.3, & \lambda_{15}^{(p)} &= 0.3,\\
\lambda_{16}^{(p)} &= 0.2, & \lambda_{17}^{(p)} &= 0.2, & \lambda_{18}^{(p)} &= 0.1, & \lambda_{19}^{(p)} &= 0.1, & \lambda_{20}^{(p)} &= 0.1,\\
\lambda_{21}^{(p)} &= 0.1, & \lambda_{22}^{(p)} &= 0.1, & \lambda_{23}^{(p)} &= 0.1, & \lambda_{24}^{(p)} &= 0.1, & \lambda_{25}^{(p)} &= 0.1,\\
\lambda_{26}^{(p)} &= 0.1, & \lambda_{27}^{(p)} &= 0.1, & \lambda_{28}^{(p)} &= 0.1, & \lambda_{29}^{(p)} &= 0.1, & \lambda_{30}^{(p)} &= 0.1,\\
\lambda_{31}^{(p)} &= 0.0, & \lambda_{32}^{(p)} &= 0.0, & \lambda_{33}^{(p)} &= 0.0, & \lambda_{34}^{(p)} &= 0.0, & \lambda_{35}^{(p)} &= 0.0,\\
\lambda_{36}^{(p)} &= 0.0, & \lambda_{37}^{(p)} &= 0.0, & \lambda_{38}^{(p)} &= 0.0, & \lambda_{39}^{(p)} &= 0.0, & \lambda_{40}^{(p)} &= 0.0,\\
\lambda_{41}^{(p)} &= 0.0
\end{alignedat}
\end{equation}

В формуле \eqref{pca_lambda41} $\lambda_{1}^{(p)},\dots, \lambda_{41}^{(p)}$ -- это доли собственных чисел ковариационной матрицы, выраженные в процентах. Начиная с  $\lambda_{18}^{(p)}$ эта доля не превышает 0.2\%. Это означает, что существует 24 компонента, которые вносят незначительный вклад в информативность данных. Метод $PCA$ не представляет возможности точно определять какие именно признаки вносят существенный вклад в информативность данных, поэтому необходимо самостоятельно выбирать и удалять признаки с низким вкладом. Было сделано предположение, что наименее информативными признаками являются: \texttt{pre\_pterm}, \texttt{pre\_fterm}, \texttt{pre\_loans\_next\_pay\_summ}, \texttt{pre\_loans\_outstanding}, \texttt{pre\_loans\_total\_over} \\ \texttt{due}, \texttt{pre\_loans\_max\_overdue\_sum}, \texttt{pre\_loans\_credit\_cost\_rate}, \texttt{is\_zero\_loans5}, 
\texttt{is\_} \texttt{zero\_loans530}, \texttt{is\_zero\_loans3060}, \texttt{is\_zero\_loans6090}, \texttt{is\_zero\_loans90}, \texttt{pre\_util}, \texttt{pre\_maxover2limit}, \texttt{is\_zero\_util},  \texttt{is\_zero\_over2limit}. 
 
 Для подтверждения необходимо повторно проделать метод $PCA$ без 16 признаков, касательно которых было сделано предположение. В листинге \ref{feat_25_py} (см. приложение 1) реализуется метод главных компонент. 

\begin{enumerate}
   \item Строки 1--2. Задаётся файл с датасетом из 25 признаков, который считывается в объект \texttt{DataFrame(df)}. 
   \item Строки 4--10. Формируется список со статусами ежемесячных платежей \texttt{enc\_paym\_k}, $k = 0,\dots,24$.
   \item Строка 12. \texttt{X\_pay = df.loc[:, columns\_pay].copy()} -- из исходного датасета \texttt{df} выбираются 25 признаков, которые формируют матрицу \texttt{X\_pay}, содержащую информацию о платёжной дисциплине.
   \item Строка 13. Создаётся объект метода главных компонент PCA с параметрами по умолчанию.
   \item Строка 14. На матрице \texttt{X\_pay} обучается модель PCA.
   \item Строка 16. Вычисляются доли объясненной дисперсии для каждого главного компонента.
\end{enumerate}

Получается следующая значимость признаков, процентно выраженная в собственных числах ковариационной матрицы  \texttt{X\_pay}.

\begin{equation}
\label{pca_lambda41_modified}
\begin{alignedat}{5} % 5 лямбда в строке
\lambda_{1}^{(p)}  &= 66.3, & \lambda_{2}^{(p)}  &= 15.6, & \lambda_{3}^{(p)}  &= 5.5, & \lambda_{4}^{(p)}  &= 2.9, & \lambda_{5}^{(p)}  &= 1.8,\\
\lambda_{6}^{(p)}  &= 1.3,  & \lambda_{7}^{(p)}  &= 1.0,  & \lambda_{8}^{(p)}  &= 0.8, & \lambda_{9}^{(p)}  &= 0.7,  & \lambda_{10}^{(p)} &= 0.6,\\
\lambda_{11}^{(p)} &= 0.5, & \lambda_{12}^{(p)} &= 0.4, & \lambda_{13}^{(p)} &= 0.4, & \lambda_{14}^{(p)} &= 0.3,  & \lambda_{15}^{(p)} &= 0.3,\\
\lambda_{16}^{(p)} &= 0.3, & \lambda_{17}^{(p)} &= 0.3, & \lambda_{18}^{(p)} &= 0.2, & \lambda_{19}^{(p)} &= 0.2,  & \lambda_{20}^{(p)} &= 0.1,\\
\lambda_{21}^{(p)} &= 0.1, & \lambda_{22}^{(p)} &= 0.1, & \lambda_{23}^{(p)} &= 0.1, & \lambda_{24}^{(p)} &= 0.1,  & \lambda_{25}^{(p)} &= 0.1.
\end{alignedat}
\end{equation}

Из формулы \eqref{pca_lambda41_modified} можно заметить, что осталось только 25 признаков, где доли собственных чисел $\lambda_{i}^{(p)}$ не равны нулю, т.е. остались те признаки, которые вносят существенный вклад в информативность данных. Однако из таблицы \ref{metrics_41} видно, что некоторые метрики для алгоритма случайного леса равны нулю, что является неприемлемым для прогнозирования кредитных рисков. Например, это метрики $Recall$ и $Precision$, для дефолтных клиентов. Таким образом, метод $PCA$ не оказал влияния на некоторые метрики алгоритма, поэтому требуется дальнейший детальный анализ.

\subsection{Определение аномального клиента}
\label{subsec:anom}

Рисунок \ref{fig:labels_before_anom} показывает, что доля недефолтных клиентов существенно велика и не соответствует статистике в реальной жизни. По данным Первого кредитного бюро Республики Казахстан около 20\%\footnote{\cite{Tengrinews} (дата обращения: 25.11.2025).}
казахстанских заемщиков имеют дефолтную кредитную историю, что подтверждает данное утверждение и указывает на наличие аномальности в классе недефолтных клиентов. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{./ch2/graphics/labels_before_anom.png}
\caption{Перекос в сторону недефолтных клиентов}
\label{fig:labels_before_anom}
\vspace{10pt}
\begin{minipage}{\textwidth}
        \fontsize{9}{11}\selectfont
        \justifying
        Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
    \end{minipage}
\end{figure}

В данной работе под аномальным клиентом понимается нетипичное поведение для большинства заемщиков. Речь идет о ситуации, когда клиент фактически не располагает достаточными денежными средствами для обслуживания кредита, однако продолжает вносить ежемесячные платежи с небольшими, но регулярными опозданиями, перезанимая необходимые суммы из других источников. В таблице \ref{table_1_1:dfgr} приведен пример неестественных выплат клиента, из которого видно, что платежная дисциплина клиента по отдельному кредиту не выглядит дефолтной, однако в среднем этот клиент не выплачивал обязательства пунктуально ни в один расчетный месяц (средние значения по месяцам представлены в последней строке таблицы). Ниже будет дано определение и алгоритм выявления таких клиентов в датасете. 

{\df Аномальным клиентом является такой клиент, для которого выполняются два условия:
\begin{equation}
\left\{
\begin{aligned}
\text{(a)}\;& \text{метка (флаг)} = 0, \\
\text{(b)}\;& \min(enc\_paym\_n) > 0,\quad n = 0,\ldots,24.
\end{aligned}
\right.
\tag{$anom$}
\label{anom}
\end{equation}
}

В формуле \eqref{anom} условие $(a)$ означает, что аномальный клиент в датасете является недефолтным, а условие $(b)$ -- по всем месяцам оплата кредитных обязательств проводилась с опозданием. В листинге \ref{anom0in1_py} (см. приложение 1) указана реализация формулы \ref{anom}. 

{\co Пояснение к листингу \ref{anom0in1_py}:} 
	\begin{enumerate}
		\item Строка 1. Читаем файл \texttt{train\_target.csv} с целевой переменной в датафрейме \texttt{df\_y}. 
		\item Строки 2--3. Из столбца \texttt{flag} датафрейма \texttt{df\_y} извлекаются метки для первых 1000000 клиентов, где \texttt{y} -- это исходные метки дефолта/недефолта, а \texttt{y\_} -- новые метки, которые будут изменяться в процессе нахождения аномальных клиентов. 
		\item Строка 5. Инициализируются счетчики \texttt{counter\_norm} -- число не аномальных клиентов, а \texttt{counter\_anom} -- число аномальных клиентов.
		\item Строка 6. Создаются пустые списки, в которые будут записываться индексы не аномальных (\texttt{ind\_norm}) и аномальных клиентов (\texttt{ind\_anom}).
		\item Строка 7. Запускается цикл по всем строкам матрицы \texttt{X\_pay}, где \texttt{i} это порядковый номер клиента (индекс строки), а \texttt{x\_pay} -- массив платежной истории по всем месяцам.
		\item Строки 8--11. Проверяется условие, которое определяет изначально недефолтных клиентов (\texttt{y\_[i] == 0}), у которых по всем месяцам наблюдаются задержки платежей (\texttt{min(x\_pay) > 0}). Если оба условия для клиента выполняются, то счетчик аномальных клиентов увеличивается на 1 (\texttt{counter\_anom +=1}) и пополняется список индексов аномальных клиентов (\texttt{ind\_anom.append(i)}), а его новой метке \texttt{y\_[i]} присваивается значение 1. Таким образом, часть клиентов, имевших исходную метку 0, переводится в класс аномальных клиентов с меткой 1. 
		\item Строки 12--14. В случае неудовлетворения этим двум условиям цикл относит клиента к не аномальным (\texttt{counter\_norm += 1}) и добавляет его индекс в список не аномальных клиентов (\texttt{ind\_norm}).
	\end{enumerate}
	
Данный алгоритм показал, что доля дефолтных клиентов увеличилась с 3.38\% до 35.45\% (см. Рисунок \ref{fig:labels_after_anom}). Это означает, что часть недефолтных клиентов перешла в класс дефолтных, и именно они  удовлетворяют определению \eqref{anom}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{./ch2/graphics/labels_after_anom.png}
\caption{Переход клиентов из класса «0» в класс «1»}
\label{fig:labels_after_anom}
\vspace{10pt}
\begin{minipage}{\textwidth}
        \fontsize{9}{11}\selectfont
        \justifying
        Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
    \end{minipage}
\end{figure}

Для большей наглядности результат переклассификации представлен на диаграмме Эйлера-Венна (см. Рисунок \ref{fig:Euler}), показывающий пересечение множеств клиентов с дефолтными и недефолтными метками. Красный круг соответствует всем клиентам с исходной недефолтной меткой (96.62\%), зеленый круг -- клиентам с дефолтной меткой (3.38\%), а их пересечение отражает группу аномальных клиентов (32.06\%).
\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{./ch2/graphics/Euler.png}
\caption{Пересечение дефолтных и недефолтных меток с выделением ошибочно недефолтных клиентов}
\label{fig:Euler}
\vspace{10pt}
\begin{minipage}{\textwidth}
        \fontsize{9}{11}\selectfont
        \justifying
        Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
    \end{minipage}
\end{figure}

Далее необходимо посмотреть как отреагирует алгоритм случайного леса на данных преобразованиях согласно определению \eqref{anom}. Под реакцией алгоритма понимается изменение точности метрик. После выявления аномальных клиентов качество модели значительно улучшилось (см. Таблицу \ref{metrics_after_rfc}). 

\begin{center}
  \begin{longtable}{|c|c|c|c|c|c|c|}
    \caption{Изменение точности метрик на признаках: $enc\_paym\_0$, \dots, $enc\_paym\_24$.}
    \label{metrics_after_rfc} \\
    \hline
    \multicolumn{7}{|c|}{Алгоритм -- Случайный лес}\\
    \hline
    \rowcolor[gray]{.9}
    \specialcell{Flag\\метка} &
    \specialcell{Precision\\точность} &
    \specialcell{Recall\\полнота} &
    \specialcell{f1--score\\f1--мера} &
    \specialcell{Accuracy\\точность}  &
    ROC--AUC &
    Количество    \\
    \hline
    \multicolumn{7}{|c|}{Тренировочная выборка}\\
    \hline
    0 & 0.99 & 0.97 & 0.98 &
    \multirow{2}{*}{0.97} &   
    \multirow{2}{*}{0.98} &  
    469239 \\                    
    \cline{1-4} \cline{7-7}
    1 & 0.94 & 0.99 & 0.96 &  
      &      & 280761 \\       
    \hline
    \multicolumn{7}{|c|}{Тестовая выборка} \\
    \hline
    0 & 0.99 & 0.97 & 0.98 &
    \multirow{2}{*}{0.97} &
    \multirow{2}{*}{0.98} &
    156325 \\
    \cline{1-4} \cline{7-7}
    1 & 0.94 & 0.99 & 0.96 & & & 93676 \\
    \hline
  \end{longtable}
  \begin{minipage}{\textwidth}
    \fontsize{9}{11}\selectfont
    \justifying
    Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
  \end{minipage}
\end{center}

Если сравнить первоначальные результаты, то можно заметить, что если до этого модель игнорировала класс дефолтных клиентов (все метрики равнялись нулю, см. Таблицу \ref{metrics_41}), то после переклассификации метрики точности стали высокими: на обучающей выборке $precision$ = 0.94, $recall$ = 0.99, $f1-score$ = 0.96, аналогичные значения показывает тестовая выборка. При этом можно качество недефолтного класса практически не ухудшилось: $precision$ снизился с 1.00 до 0.99, а метрики $recall$ и $f1-score$ не изменились. Также $ROC\ AUC$ увеличился с 0.51 до 0.97, что свидетельствует о том, что теперь модель хорошо различает дефолтных и недефолтных клиентов. Одновременно увеличилось количество дефолтных клиентов в выборках за счет вновь выявленных аномальных наблюдений, что позволило алгоритму случайного леса показать эффективные результаты на обоих классах. 

\subsection{Статистический тест Колмогорова-Смирнова}

Понятие аномального клиента, изложенное в разделе \ref{subsec:anom}, основано на анализе платежного поведения заемщиков. Применение данного подхода привело к существенному улучшению метрик точности алгоритма случайного леса. Поэтому на следующем шаге проводится статистический анализ, позволяющий увидеть и обосновать, насколько поведение аномальных клиентов отличается от поведения дефолтных клиентов. Для проверки равенства (неравенства) функций распределения двух выборок применяется критерий Колмогорова-Смирнова. А.Н. Колмогоровым\footnote{Колмогоров А.Н. (1903-1987 гг.) -- Герой Социалистического Труда, профессор Московского государственного университета, академик АН СССР -- крупнейший математик XX века, является одним из основоположников современной теории вероятности.} и Н.В. Смирновым\footnote{Смирнов Н.В. (1900-1966 гг.) -- член-корреспондент АН СССР, один из создателей непараметрических методов математической статистики и теории предельных распределений порядковых статистик.} была доказана следующая теорема:

{\theorem Пусть $F_{X_1}(x)$, $F_{X_2}(x)$ -- выборочные функции распределения
двух независимых выборок объёмами $n$ и $m$. Обозначим:
\[
D_{n,m} = \sup_x \bigl| F_{X_1}(x) - F_{X_2}(x) \bigr|.
\]
}

Тогда для любого $t>0$ выполняется:
\begin{equation}
\forall t>0:\quad
\lim_{n,m\to\infty}
P\!\left(
\sqrt{\frac{nm}{n+m}}\, D_{n,m} \le t
\right)
= K(t)
= \sum_{j=-\infty}^{+\infty} (-1)^j e^{-2 j^2 t^2}.
\label{eq:smirnov_theorem}
\end{equation}

На основе статистики $D_{n,m}$ строится статистика критерия
\[
t_{n,m} = \sqrt{\frac{nm}{n+m}}\, D_{n,m}.
\]

С помощью этой статистики проверяются нулевая и альтернативная гипотезы о совпадении распределений двух выборок:
\[
\begin{cases}
\mathcal{H}_0: F_{X_1}(x) = F_{X_2}(x),\\
\mathcal{H}_1: F_{X_1}(x) \neq F_{X_2}(x).
\end{cases}
\]

При заданном уровне значимости $\alpha$ выбирается критическое значение $K_\alpha$ распределения Колмогорова. Правило принятия решения имеет следующий вид:
\[
\begin{cases}
t_{n,m} \le K_\alpha, & \text{нулевая гипотеза } \mathcal{H}_0 \text{ принимается},\\
t_{n,m} > K_\alpha, & \text{нулевая гипотеза } \mathcal{H}_0 \text{ отвергается в пользу } \mathcal{H}_1.
\end{cases}
\]

Для применения критерия Колмогорова-Смирнова клиенты были разделены на две подвыборки:

\[
\begin{cases}
	X_1 \coloneqq X_{1 \to 1}, \textit{\quad (default)},\\
	X_2 \coloneqq X_{0 \to 1}, \textit{\quad (anom)},
\end{cases}
\] где $X_1$ -- выборка клиентов, являющихся дефолтными до и после условия аномальности;
$X_2$ --  выборка  клиентов, у которых метка изменилась с «0» на «1».

Задача состоит в том, чтобы выяснить, принадлежат ли выборки $X_1$ и $X_2$ одному распределению, применив критерий Колмогорова-Смирнова. Если выборки $X_1$ и $X_2$ принадлежат одному распределению (принятие гипотезы $\mathcal{H}_0$), то платежная дисциплина дефолтных и аномальных клиентов одинакова. Критерий Колмогорова-Смирнова реализуется в листинге \ref{kolmogorov_py} (см. приложение 1). 
{\co Пояснение к листингу \ref{kolmogorov_py}:} 
\begin{enumerate}
	\item Строки 1--2. Выбирается признак за 15 месяц \texttt{enc\_paym\_15} и соответствующий столбец из \texttt{X\_pay} сохраняется в переменную \texttt{T}. 
	\item Строки 3--4. Формируются три выборки по этому признаку: \texttt{x00} -- клиенты с меткой «0» до и после выявления аномальных клиентов; \texttt{x01} -- аномальные клиенты, у которых изменилась метка с «0» на «1» после выявления аномальности; \texttt{x11} -- клиенты с меткой «1» до и после выявления аномальных клиентов.
	\item Строки 5--7. Происходит фильтрация выборок \texttt{x00}, \texttt{x01}, \texttt{x11}, у которых отбрасываются наблюдения с платежными статусами 0, 1, 2, 3, 4, 5, поскольку агрегация данных была произведена по среднему значению.
	\item Строка 10. Определяется функция \texttt{my\_cdf} по двум выборкам \texttt{x1} и \texttt{x2}.
	\item Строка 11. Выбирается максимальное значение (опоздание) из этих двух выборок.
	\item Строка 12. Создаются пустые списки \texttt{F1} и \texttt{F2}, в которые будут записываться значения. 
	\item Строка 13. Определяется длина выборок \texttt{x1} и \texttt{x2}, состоящих из положительных значений.
	\item Строки 14--16. В цикле для каждой точки \texttt{tm} с шагом 0.01 считается сколько наблюдений для выборок \texttt{x1} и \texttt{x2} попадают в интервал (0; $t$). 
	\item Строки 17--19. Вычисляется вероятность каждой точки и получаются значения функции распределения ($CDF$). Далее считается статистика Колмогорова по формуле: $ \sup_x \bigl| F_{X_1}(x) - F_{X_2}(x) \bigr| \sqrt{\frac{nm}{n+m}}$.
	\item Строки 20--23. Задается шаг \texttt{step = 0.01} и вычисляются значения функции распределения $CDF$ для пары «аномальных и дефолтных», а затем для «аномальных и недефолтных» клиентов.
\end{enumerate}

Датасет содержит 25 дисциплинарных признаков ($enc\_paym\_0$, \dots, $enc\_paym\_24$), и для каждого из них необходимо применить данный тест, чтобы выяснить, для каких признаков принимается та или иная гипотеза. Поскольку в датасете 3\,000\,000 наблюдений (объемы выборок $n$ и $m$ велики), то при уровне значимости $\alpha$ = 0.05 в качестве критического значения используется $K_\alpha$ = 1.36. 

Анализ показал, что первые 15 месяцев ($enc\_paym\_0$, \dots, $enc\_paym\_14$) поведение аномальных клиентов отличается от поведения дефолтных, а начиная с 16 по 25 месяц ($enc\_paym\_15$, \dots, $enc\_paym\_24$), поведение становится схожим. Так, например, для 15 месяца ($enc\_paym\_14)$ (см. Рисунок \ref{enc_paym_14_def.png}) расчетное значение статистики $t_{n,m}$ = 1.41. Поскольку $K_\alpha$ = 1.36 и $t_{n,m}$ > $K_\alpha$, принимается гипотеза $\mathcal{H}_1$. Это означает, что финансовое поведение аномальных клиентов, раннее относившихся к классу «0», отличается от поведения дефолтных клиентов. 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{./ch2/graphics/enc_paym_14_def.png}
	\caption{Функции распределения и функции плотностей распределения дефолтных и аномальных клиентов}
	\label{enc_paym_14_def.png}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

Для 16 месяца $(enc\_paym\_15)$ (см. Рисунок \ref{enc_paym_15_def.png}) значение $t_{n,m}$ = 1.31. В этом случае $t_{n,m}$ < $K_\alpha$, поэтому принимается гипотеза $\mathcal{H}_0$. Распределения значений признака для аномальных и дефолтных клиентов не различаются.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{./ch2/graphics/enc_paym_15_def.png}
	\caption{Функции распределения и функции плотностей распределения дефолтных и аномальных клиентов}
	\label{enc_paym_15_def.png}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

Таким образом, поведение аномальных и дефолтных клиентов до 15 месяца различно, а начиная с 16 месяца их поведение становится схожим. Возникает следующий вопрос, если поведение аномальных клиентов отличается от поведения дефолтных ($enc\_paym\_15$, \dots, $enc\_paym\_24$), то не является ли оно более близким к поведению недефолтных клиентов. 

При сравнении аномальных и недефолтных клиентов анализ показал, что за 15 месяц (см. Рисунок \ref{enc_paym_14_nodef.png}) их выплаты также существенно различались, поскольку при значении статистики $t_{n,m}$ = 70.92 и условии $t_{n,m}$ > $K_\alpha$ принимается гипотеза $\mathcal{H}_1$, что свидетельствует об их абсолютном различии по поведению.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{./ch2/graphics/enc_paym_14_nodef.png}
	\caption{Функции распределения и функции плотностей распределения недефолтных и аномальных клиентов}
	\label{enc_paym_14_nodef.png}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

Если сравнить поведение аномальных и недефолтных клиентов за 16 месяц (см. Рисунок \ref{enc_paym_15_nodef.png}), то также наблюдается существенное различие. Расчетное значение статистики $t_{n,m}$ = 68.6 и поскольку $t_{n,m}$ > $K_\alpha$, принимается гипотеза $\mathcal{H}_1$.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{./ch2/graphics/enc_paym_15_nodef.png}
	\caption{Функции распределения и функции плотностей распределения недефолтных и аномальных клиентов}
	\label{enc_paym_15_nodef.png}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

В результате анализа при сравнении аномальных и дефолтных клиентов была выявлена их схожесть после 16 месяца, тогда как при сравнении аномальных и недефолтных за весь рассматриваемый период наблюдается устойчивое расхождение. Для наглядности результаты сведены в следующую таблицу (см. Таблицу \ref{tab:ks_enc_paym}).

\begin{table}[H]
	\centering
	\caption{Результаты критерия Колмогорова--Смирнова за 25 месяцев}
	\label{tab:ks_enc_paym}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{Месяц} &
		\multicolumn{2}{c|}{Аномальные и дефолтные клиенты} &
		\multicolumn{2}{c|}{Аномальные и недефолтные клиенты} \\
		\cline{2-5}
		& Статистика & \specialcell{Принятие\\гипотезы} & Статистика & \specialcell{Принятие\\гипотезы} \\
		\hline
		\texttt{enc\_paym\_0} & $t_{n,m}$ = 1.65, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 61.40, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_1}  & $t_{n,m}$ = 2.49, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 72.44, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_2}  & $t_{n,m}$ = 3.09, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 62.21, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_3}  & $t_{n,m}$ = 3.33, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 62.03, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_4}  & $t_{n,m}$ = 3.29, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 63.85, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_5}  & $t_{n,m}$ = 3.20, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 65.22, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_6}  & $t_{n,m}$ = 2.88, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 67.04, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_7}  & $t_{n,m}$ = 2.50, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 61.43, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_8}  & $t_{n,m}$ = 2.28, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 56.28, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_9}  & $t_{n,m}$ = 2.00, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 60.88, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_10} & $t_{n,m}$ = 1.90, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 68.11, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_11} & $t_{n,m}$ = 1.85, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 71.93, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_12} & $t_{n,m}$ = 1.72, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 74.84, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_13} & $t_{n,m}$ = 1.53, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 73.55, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_14} & $t_{n,m}$ = 1.41, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$  & $t_{n,m}$ = 70.92, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_15} & $t_{n,m}$ = 1.31, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 68.86, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_16} & $t_{n,m}$ = 1.17, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 68.26, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_17} & $t_{n,m}$ = 1.03, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 67.03, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_18} & $t_{n,m}$ = 0.99, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 65.48, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_19} & $t_{n,m}$ = 0.84, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 64.54, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_20} & $t_{n,m}$ = 0.79, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 62.74, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_21} & $t_{n,m}$ = 0.80, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 60.50, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_22} & $t_{n,m}$ = 0.80, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 58.80, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_23} & $t_{n,m}$ = 0.80, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 57.53, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
		\texttt{enc\_paym\_24} & $t_{n,m}$ = 0.68, $t_{n,m}$ < $K_\alpha$ & $\mathcal{H}_0$  & $t_{n,m}$ = 53.10, $t_{n,m}$ > $K_\alpha$ & $\mathcal{H}_1$ \\ \hline
	\end{tabular}
	
	\vspace{3mm} 
	
	\begin{minipage}{0.98\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Примечание: $K_\alpha$ = 1.36 при уровне значимости $\alpha$ = 0.05.
	\end{minipage}
\end{table}

Из результатов применения критерия Колмогорова-Смирнова (см. Таблицу \ref{tab:ks_enc_paym}) видно, что все значения статистики  $t_{n,m}$ при сравнении распределений $F_{X_{01}}(x)$ и $F_{X_{11}}(x)$ меньше, чем при сравнении $F_{X_{01}}(x)$ и $F_{X_{00}}(x)$. Отсюда следует, что аномальные клиенты по своему платежному поведению ближе к классу дефолтных заемщиков, чем к недефолтным.

\subsection{Сильная корреляция соседних признаков}

Для последующей редукции признакового пространства и улучшения метрик алгоритмов была проанализирована корреляция Пирсона\footnote{Пирсон К. (1857-1936 гг.) -- британский математик, один из основоположников математической статистики.} соседних признаков $enc\_paym\_0$, \dots, $enc\_paym\_24$. На практике некоторые признаки могут дублировать друг друга (явление мультиколлинеарности) и следовательно из пары сильно коррелирующих признаков необходимо оставить только один признак. В работе были выделены три группы клиентов: недефолтные (0), дефолтные (1) и аномальные ($0 \to 1$). Для детального анализа построен график (см. Рисунок \ref{group_corr}), на котором представлены четыре коэффициента корреляции:
\begin{enumerate}
	\item $corr\_all$ -- общий коэффициент корреляции;
	\item $corr\_nodefault$ -- коэффициент корреляции для недефолтных клиентов; 
	\item $corr\_default$ --  коэффициент корреляции для дефолтных клиентов; 
	\item $corr\_anom$ -- коэффициент корреляции для аномальных клиентов.
\end{enumerate}

Видно, что платежная дисциплина аномальных и дефолтных клиентов схожа друг с другом в отличие от аномальных и недефолтных клиентов. %В качестве среднего значения, с которым сравниваются три группы выделяется четвертая группа $corr\_all$. 
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{./ch2/graphics/group_corr.png}
	\caption{Изменение корреляции между соседними признаками}
	\label{group_corr}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

 В таблице указаны значения коэффициентов корреляции и теста Фишера\footnote{Фишер. Р.Э. (1890-1962 гг.) -- британский статистик, один из основателей математической статистики и математической популяционной генетики.} на равенство выборочного коэффициента корреляции ($r$) некоторому теоретическому коэффициенту корреляции ($R$) всех значений соседних признаков. Фишер показал, что статистика ($z$-преобразование Фишера):
 \[
 z(r) = \frac{1}{2}\ln\frac{1+r}{1-r} \textit{\quad (Fisher)}
 \] 
 имеет приближенно нормальное распределение 
 \[
 z(r) \sim N\!\left(\frac{1}{2}\ln\frac{1+R}{1-R},\,\frac{1}{n-3}\right),
 \]
 где $R$ -- некоторый теоретический коэффициент корреляции, $n$ -- объем выборки, $r$ -- выборочный коэффициент корреляции.
 
В качестве теоретического коэффициента корреляции ($R$) в исследовании используется коэффициент корреляции всей совокупности клиентов для соответствующих значений соседних признаков. Для каждой из трех групп (недефолтных, дефолтных и аномальных клиентов) вычисляется свой выборочный коэффициент корреляции ($r$). Далее проверяется гипотеза о равенстве корреляций выборочной и генеральной совокупностей:

\[
\begin{cases}
	\mathcal{H}_0: r = R, \\
	\mathcal{H}_1: r \neq R.
\end{cases}
\]
В качестве статистики критерия Фишера используется величина

\[
t = \frac{z(r) - z(R)}{\sqrt{\frac{1}{n-3}}}
\]
При заданном уровне значимости $\alpha$ гипотеза принимается в случаях:

\[
\begin{cases}
	|t| \le t_{\text{crit}}, & \text{нулевая гипотеза } H_0 \text{ не отвергается},\\[2mm]
	|t| > t_{\text{crit}},  & \text{нулевая гипотеза } H_0 \text{ отвергается в пользу } H_1.
\end{cases}
\]

Если посмотреть на эти коэффициенты корреляции в разрезе для каждой группы %(см. Рисунок \ref{cmap},) 
(см. Таблицу \ref{tab:fisher_r_enc_paym}), то можно заметить, что начиная со сравнения 16 и 17 месяцев (см. Листинг \ref{fisher_py}), коэффициент корреляции одной из трех групп принимает гипотезу $\mathcal{H}_0$:$|t| < t_{crit}$. Такая тенденция прослеживается до сравнения 20 и 21 месяца. Поскольку финансовая дисциплина в соседних месяцах схожа друг с другом, то принимается решение об исключении сильно коррелирующих признаков. В таком случае исключаются пять признаков: $enc\_paym\_16$, \dots, $enc\_paym\_20$. 

%\begin{figure}[H]
%	\centering
%	\includegraphics[scale=0.3]{./ch2/graphics/cmap.png}
%	\caption{Корреляция между соседними признаками по группам}
%	\label{cmap}
%	\vspace{10pt}
%	\begin{minipage}{\textwidth}
%		\fontsize{9}{11}\selectfont
%		\justifying
%		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
%	\end{minipage}
%\end{figure}

\begin{table}[H]
	\centering
	\caption{Результаты теста Фишера за 25 месяцев}
	\label{tab:fisher_r_enc_paym}
	\scalebox{0.85}{
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{Месяц} &
		\multicolumn{2}{c|}{$r_{\text{nodefault}}$} &
		\multicolumn{2}{c|}{$r_{\text{default}}$} &
		\multicolumn{2}{c|}{$r_{\text{anom}}$} &
		$r_{\text{all}}$ \\
		\cline{2-8}
		& Статистика & \specialcell{Гипотеза}
		& Статистика & \specialcell{Гипотеза}
		& Статистика & \specialcell{Гипотеза}
		& Статистика \\
		\hline
		\specialcell{\texttt{enc\_paym\_1}\\\texttt{enc\_paym\_2}} &
		\specialcell{$t_{nod} = 505.11$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 195.08$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 238.49$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.63$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_1}\\\texttt{enc\_paym\_2}} &
		\specialcell{$t_{nod} = 132.87$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 160.51$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 183.05$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.80$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_2}\\\texttt{enc\_paym\_3}} &
		\specialcell{$t_{nod} = 95.71$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 133.53$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 147.53$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.85$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_3}\\\texttt{enc\_paym\_4}} &
		\specialcell{$t_{nod} = 74.37$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 120.26$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 136.01$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.87$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_5}\\\texttt{enc\_paym\_6}} &
		\specialcell{$t_{nod} = 50.52$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 76.73$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 84.20$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.88$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_6}\\\texttt{enc\_paym\_7}} &
		\specialcell{$t_{nod} = 40.55$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 66.10$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 75.36$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.91$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_7}\\\texttt{enc\_paym\_8}} &
		\specialcell{$t_{nod} = 34.57$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 61.13$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 71.94$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.92$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_8}\\\texttt{enc\_paym\_9}} &
		\specialcell{$t_{nod} = 30.71$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 58.64$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 64.91$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.93$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_9}\\\texttt{enc\_paym\_{10}}} &
		\specialcell{$t_{nod} = 21.29$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 36.56$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 37.83$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.92$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{10}}\\\texttt{enc\_paym\_{11}}} &
		\specialcell{$t_{nod} = 16.36$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 26.75$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 31.11$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.93$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{11}}\\\texttt{enc\_paym\_{12}}} &
		\specialcell{$t_{nod} = 11.00$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 14.11$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 15.34$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.91$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{12}}\\\texttt{enc\_paym\_{13}}} &
		\specialcell{$t_{nod} = 4.13$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 3.23$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 4.54$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.93$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{13}}\\\texttt{enc\_paym\_{14}}} &
		\specialcell{$t_{nod} = 6.38$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 4.42$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 14.78$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.96$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{14}}\\\texttt{enc\_paym\_{15}}} &
		\specialcell{$t_{nod} = 8.39$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 11.74$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 21.25$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.96$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{15}}\\\texttt{enc\_paym\_{16}}} &
		\specialcell{$t_{nod} = 2.57$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 3.57$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 6.86$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.97$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{16}}\\\texttt{enc\_paym\_{17}}} &
		\specialcell{$t_{nod} = 4.14$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 1.81$\\$|t_{def}| \le t_{crit}$} & $\mathcal{H}_0$ &
		\specialcell{$t_{ano} = 11.66$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.97$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{17}}\\\texttt{enc\_paym\_{18}}} &
		\specialcell{$t_{nod} = 1.68$\\$|t_{nod}| \le t_{crit}$} & $\mathcal{H}_0$ &
		\specialcell{$t_{def} = 13.57$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 5.95$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.97$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{18}}\\\texttt{enc\_paym\_{19}}} &
		\specialcell{$t_{nod} = 1.12$\\$|t_{nod}| \le t_{crit}$} & $\mathcal{H}_0$ &
		\specialcell{$t_{def} = 11.44$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 7.87$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.97$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{19}}\\\texttt{enc\_paym\_{20}}} &
		\specialcell{$t_{nod} = 0.71$\\$|t_{nod}| \le t_{crit}$} & $\mathcal{H}_0$ &
		\specialcell{$t_{def} = 9.48$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 1.87$\\$|t_{ano}| \le t_{crit}$} & $\mathcal{H}_0$ &
		$t_{all} = 0.97$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{20}}\\\texttt{enc\_paym\_{21}}} &
		\specialcell{$t_{nod} = 0.64$\\$|t_{nod}| \le t_{crit}$} & $\mathcal{H}_0$ &
		\specialcell{$t_{def} = 5.11$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 3.21$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.97$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{21}}\\\texttt{enc\_paym\_{22}}} &
		\specialcell{$t_{nod} = 2.86$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 14.00$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 5.77$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.97$ \\ \hline
		
		\specialcell{\texttt{enc\_paym\_{22}}\\\texttt{enc\_paym\_{23}}} &
		\specialcell{$t_{nod} = 3.48$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 15.23$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 13.21$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.97$ \\ \hline
	
		\specialcell{\texttt{enc\_paym\_{23}}\\\texttt{enc\_paym\_{24}}} &
		\specialcell{$t_{nod} = 22.36$\\$|t_{nod}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{def} = 69.20$\\$|t_{def}| > t_{crit}$} & $\mathcal{H}_1$ &
		\specialcell{$t_{ano} = 66.41$\\$|t_{ano}| > t_{crit}$} & $\mathcal{H}_1$ &
		$t_{all} = 0.79$ \\ \hline
	\end{tabular} 
}

\end{table}

\begin{minipage}{0.98\textwidth}
	\fontsize{9}{11}\selectfont
	\justifying
	Примечание: $t_{crit}$ = 1.96 при уровне значимости $\alpha$ = 0.05.
\end{minipage}


\section{Базовые алгоритмы оценки вероятности возврата кредита}
\subsection{Деревья решений}
Необходимо протестировать предобработанные данные на таких базовых алгоритмах, как деревья решений ($Decision\ Tree$), случайный лес ($Random Forest$), градиентный бустинг ($Gradient Boosting$) и нейронные сети ($Neural Networks$). Важно отметить, что алгоритмы тестируются на 1\,000\,000 данных и полученные метрики точности будут сраниваться с метриками, которые будут получены после тестирования на больших данных (3\,000\,000 клиентов). Тестирование на небольших данных проводится с целью экономии объема оперативной памяти. 

Результаты метрик точности позволяют понять насколько хорошо модель справляется с задачей классификации. Для этого необходимо выявить одно из двух явлений: переобучение или недообучение. Переобучение -- явление, когда алгоритм хорошо распознает объекты из обучающей (тренировочной) выборки, но хуже их классифицирует на тестовой выборке. Модель стремится запомнить все возможные примеры из обучающих данных, вместо того, чтобы научиться выявлять особенности. Недообучение -- явление, при котором простая модель не успевает уловить сложные закономерности между признаками и меткой дефолта. В этом случае алгоритм показывает низкие метрики на обучающей и тестовой выборках, т.е. модель плохо разделяет надежных и рискованных клиентов даже на тех данных, на которых она обучалась.

Деревья решений ($Decision Tree$) -- это один из алгоритмов МО, который по шагам делит заемщиков на группы с помощью последовательных вопросов вида «да» или «нет»\footnote{\cite{WangHuan} (дата обращения 25.11.2025).}. На каждом шаге выбирается такой признак, который сильнее влияет на результат, а в конечных вершинах алгоритм выдает прогноз вероятности дефолта клиента.

Результаты алгоритма решающих деревьев (см. Таблицу \ref{metrics_dtr}) демонстрируют высокую точность. Видно, что метрики класса «0» на тренировочной выборке: $precision$ = 1.00, $recall$ = 0.99, $f1-score$ = 0.99 выше в отличие от тестовой выборки, где $precision$ = 0.98, $recall$ = 0.97, $f1-score$ = 0.97. Это означает, что алгоритм лучше распознает недефолтных клиентов на тренировочных данных, чем на тестовых. Аналогичная ситуация наблюдается у класса «1», где на тренировочных данных метрики выше, чем на тестовых. При этом результаты на двух выборках ниже, чем у «0» класса, что указывает на то, что дефолтные клиенты хуже распознаются. 

\newpage
\begin{center}
	\begin{longtable}{|c|c|c|c|c|c|c|}
		\caption{Метрики точности алгоритма Decision Tree на 1\,000\,000 данных}
		\label{metrics_dtr} \\
		\hline
%		\multicolumn{7}{|c|}{Алгоритм -- Случайный лес}\\
		\hline
		\rowcolor[gray]{.9}
		\specialcell{Flag\\метка} &
		\specialcell{Precision\\точность} &
		\specialcell{Recall\\полнота} &
		\specialcell{f1--score\\f1--мера} &
		\specialcell{Accuracy\\точность}  &
		ROC--AUC &
		Количество    \\
		\hline
		\multicolumn{7}{|c|}{Тренировочная выборка}\\
		\hline
		0 & 1.00 & 0.99 & 0.99 &
		\multirow{2}{*}{0.99} &   
		\multirow{2}{*}{0.99} &  
		469239 \\                    
		\cline{1-4} \cline{7-7}
		1 & 0.98 & 1.00 & 0.99 &  
		&      & 280761 \\       
		\hline
		\multicolumn{7}{|c|}{Тестовая выборка} \\
		\hline
		0 & 0.98 & 0.97 & 0.97 &
		\multirow{2}{*}{0.97} &
		\multirow{2}{*}{0.97} &
		156325 \\
		\cline{1-4} \cline{7-7}
		1 & 0.95 & 0.96 & 0.96 & & & 93676 \\
		\hline
	\end{longtable}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{center}

Также метрики $accuracy$ и $ROC-AUC$ (см. Рисунок \ref{ROC_AUC_DT_train_test}) выше на тренировочной выборке, чем на тестовой. Следовательно, можно сделать вывод о наличии переобучения алгоритма $Decision\ Tree$.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{./ch2/graphics/ROC_AUC_DT_train_test.png}
	\caption{Метрика ROC--AUC на тренировочных и тестовых данных алгоритма Decision Tree}
	\label{ROC_AUC_DT_train_test}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

Для более подробной картины приведена матрица ошибок (см. Таблицу \ref{matrix_dtr_train_test}). На тренировочных данных верно классифицированы 469\,223 недефолтных и 275\,761 дефолтных клиентов. При этом 5000 недефолтных клиентов ошибочно отнесены к дефолтным, и только 16 дефолтов алгоритм принял за недефолт. 

На тестовой выборке алгоритм больше ошибается. Верно распознаны 152\,717 недефолтных и 89\,213 дефолтных клиентов. Алгоритм ошибочно принял 4\,463 недефолта за дефолт, и 3\,608 дефолтов за недефолт. Таким образом, матрица ошибок указывает на ухудшение предсказаний решающих деревьев на тестовых данных, что подтверждает вывод о переобучении данного алгоритма.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{./ch2/graphics/matrix_dtr_train_test.png}
	\caption{Матрица ошибок на тренировочных и тестовых данных алгоритма Decision Tree}
	\label{matrix_dtr_train_test}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

\subsection{Случайный лес}

Случайный лес ($Random Forest$) -- это алгоритм МО, состоящий из множества отдельных независимых деревьев решений. Каждое дерево выдает свое предсказание по возврату кредита, а затем итоговое предсказание определяется по принципу большинства.

Алгоритм случайного леса также показывает высокие результаты распознования клиентов (см. Таблицу \ref{metrics_rfc}). Можно заметить, что метрики класса «0» $recall$ и $f1-score$ на тренировочных данных выше, чем на тестовых, а метрика $precision$ остается на одинаково высоком уровне. Метрики класса «1» $precision$ и $f1-score$ также на тренировочной выборке выше, чем на тестовой.

\begin{center}
	\begin{longtable}{|c|c|c|c|c|c|c|}
		\caption{Метрики точности алгоритма Random Forest на 1\,000\,000 данных}
		\label{metrics_rfc} \\
		\hline
		%		\multicolumn{7}{|c|}{Алгоритм -- Случайный лес}\\
		\hline
		\rowcolor[gray]{.9}
		\specialcell{Flag\\метка} &
		\specialcell{Precision\\точность} &
		\specialcell{Recall\\полнота} &
		\specialcell{f1--score\\f1--мера} &
		\specialcell{Accuracy\\точность}  &
		ROC--AUC &
		Количество    \\
		\hline
		\multicolumn{7}{|c|}{Тренировочная выборка}\\
		\hline
		0 & 1.00 & 0.99 & 0.99 &
		\multirow{2}{*}{0.99} &   
		\multirow{2}{*}{0.99} &  
		469239 \\                    
		\cline{1-4} \cline{7-7}
		1 & 0.98 & 1.00 & 0.99 &  
		&      & 280761 \\       
		\hline
		\multicolumn{7}{|c|}{Тестовая выборка} \\
		\hline
		0 & 1.00 & 0.97 & 0.98 &
		\multirow{2}{*}{0.98} &
		\multirow{2}{*}{0.98} &
		156325 \\
		\cline{1-4} \cline{7-7}
		1 & 0.95 & 1.00 & 0.97 & & & 93676 \\
		\hline
	\end{longtable}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{center}

Метрики $accuracy$ и $ROC-AUC$ (см. Рисунок  \ref{ROC_AUC_RF_train_test}) показывают небольшую разницу между тренировочными и тестовыми данными.  Это также, как и в предыдущем алгоритме указывает на склонность случайного леса к переобучению.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{./ch2/graphics/ROC_AUC_RF_train_test.png}
	\caption{Метрика ROC--AUC на тренировочных и тестовых данных алгоритма Random Forest}
	\label{ROC_AUC_RF_train_test}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

Если посмотреть в количественном разрезе (см. Рисунок \ref{matrix_rfc_train_test}), то на тренировочных данных алгоритм 469\,194 недефолтных клиентов определяет верно, а 4\,982 неверно относит к недефолтным. Также 275\,779 дефолтов алгоритм правильно определяет, но 45 клиентов неверно отнесены к недефолтным. 

На тестовых данных случайный лес показывает хуже результат: 156\,170 недефолтных клиентов правильно распознаются, а 4\,600 неверно определяются как дефолтные. Также 89\,076 дефолтов правильно классифицируются, однако 155 ошибочно относятся к недефолтным. Поэтому матрица ошибок также обосновывает склонность случайного леса к переобучению.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{./ch2/graphics/matrix_rfc_train_test.png}
	\caption{Матрица ошибок на тренировочных и тестовых данных алгоритма Random Forest}
	\label{matrix_rfc_train_test}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

\subsection{Градиентный бустинг}

Градиентный бустинг ($Gradient\ Boosting$) -- комбинация множества простых алгоритмов деревьев решений, где каждый новый алгоритм исправляет ошибки предыдущего.

Все метрики точности алгоритма градиентного бустинга (см. Таблицу \ref{metrics_grb}) обоих классов показывают высокие результаты, что делает данную модель почти идеальной. Небольшим недостатком является более низкая точность метрик класса «1» на обеих выборках, что свидетельствует о более высокой ошибочной вероятности предсказаний на дефолтных клиентах.

\begin{center}
	\begin{longtable}{|c|c|c|c|c|c|c|}
		\caption{Метрики точности алгоритма Gradient Boosting на 1\,000\,000 данных}
		\label{metrics_grb} \\
		\hline
		%		\multicolumn{7}{|c|}{Алгоритм -- Случайный лес}\\
		\hline
		\rowcolor[gray]{.9}
		\specialcell{Flag\\метка} &
		\specialcell{Precision\\точность} &
		\specialcell{Recall\\полнота} &
		\specialcell{f1--score\\f1--мера} &
		\specialcell{Accuracy\\точность}  &
		ROC--AUC &
		Количество    \\
		\hline
		\multicolumn{7}{|c|}{Тренировочная выборка}\\
		\hline
		0 & 0.99 & 0.97 & 0.98 &
		\multirow{2}{*}{0.98} &   
		\multirow{2}{*}{0.98} &  
		469239 \\                    
		\cline{1-4} \cline{7-7}
		1 & 0.95 & 0.99 & 0.97 &  
		&      & 280761 \\       
		\hline
		\multicolumn{7}{|c|}{Тестовая выборка} \\
		\hline
		0 & 0.99 & 0.97 & 0.98 &
		\multirow{2}{*}{0.98} &
		\multirow{2}{*}{0.98} &
		156325 \\
		\cline{1-4} \cline{7-7}
		1 & 0.95 & 0.99 & 0.97 & & & 93676 \\
		\hline
	\end{longtable}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{center}

Также это могут подтвердить метрики $accuracy$ и $ROC-AUC$ (см. Рисунок \ref{ROC_AUC_GRB_train_test}), которые показывают идентичные результаты на обеих выборках. Это делает алгоритм градиентного бустинга наиболее предпочтительным в прогнозировании дефолта.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{./ch2/graphics/ROC_AUC_GRB_train_test.png}
	\caption{Метрика ROC--AUC на тренировочных и тестовых данных алгоритма Gradient Boosting}
	\label{ROC_AUC_GRB_train_test}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

Матрица ошибок (см. Рисунок \ref{matrix_grb_train_test}) показывает, что на тренировочных данных алгоритм правильно определяет 466\,682 недефолтных клиентов, а 13\,404 ошибочно относит к дефолтным. Верно классифицирует 267\,357 дефолтных клиентов, а 2\,557 неверно предсказывает как недефолтных. На тестовых данных неверно относит 4\,561 недефолтных клиентов к дефолтным, а 868 дефолтных к недефолтным, что указывает на сбалансированность предсказаний алгоритма. 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{./ch2/graphics/matrix_grb_train_test.png}
	\caption{Матрица ошибок на тренировочных данных алгоритма Gradient Boosting}
	\label{matrix_grb_train_test}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

\subsection{Нейронные сети}

Нейронные сети ($Neural Networks$) -- математическая модель, позволяющая компьютерам имитировать работу человеческого мозга. Она состоит из множества простых узлов, которые образуют нейроны, сгруппированных в слои. Главными задачами нейронных сетей являются распознование скрытых закономерностей в данных и делать прогноз. В данной работе используется нейронная сеть, состоящая из трех слоев (см. Рисунок \ref{neural_network_structure}): 

	\begin{enumerate}
	\item входной слой -- состоит из 25 нейронов (равен количеству дисциплинарных признаков: $enc\_paym\_0$, \dots, $enc\_paym\_24$);
	\item скрытый слой -- 32 нейрона;
	\item выходной слой -- 1 нейрон, который дает оценку вероятности ($p$) дефолта заемщика.
	\end{enumerate}
	
На вход передаются значения платежной дисциплины клиентов $enc\_paym\_0$, \dots, $enc\_paym\_24$. Далее 25 признаков поступают в скрытый слой, состоящий из 64 нейронов. Каждому признаку присваивается свой вес важности и вычисляется его взвешенная сумма. К полученной сумме применяется функция активации (в данной работе используется $ReLu$), которая «включает» нейрон, если суммарный сигнал превышает пороговое значение. В таком случае нейрон передает сигнал каждому связанному с ним нейроном в следующем слое. Если сумма ниже порогового значения, то нейрон «выключается» и данный признак является незначимым. В скрытом слое образуются 64 различные комбинации для 25 признаков и далее каждый из 64 нейронов выдает собственную оценку вероятности. В выходном слое из полученных 64 сигналов выбирается ответ с наибольшим весом. Таким образом, формируется ответ заемщику о выдаче или отказе в кредите.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8]{./ch2/graphics/neural_network.png}
	\caption{Структура нейронной сети для оценки вероятности дефолта заемщика}
	\label{neural_network_structure}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе программы Lucidchart (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

Результаты нейронной сети (см. Таблицу \ref{metrics_nn}), как и градиентного бустинга показывает высокую точность распознования клиентов, но также имеет выше вероятность ошибочного предсказания на дефолтных клиентах.

\begin{center}
	\begin{longtable}{|c|c|c|c|c|c|c|}
		\caption{Метрики точности алгоритма Neural Network на 1\,000\,000 данных}
		\label{metrics_nn} \\
		\hline
		%		\multicolumn{7}{|c|}{Алгоритм -- Случайный лес}\\
		\hline
		\rowcolor[gray]{.9}
		\specialcell{Flag\\метка} &
		\specialcell{Precision\\точность} &
		\specialcell{Recall\\полнота} &
		\specialcell{f1--score\\f1--мера} &
		\specialcell{Accuracy\\точность}  &
		ROC--AUC &
		Количество    \\
		\hline
		\multicolumn{7}{|c|}{Тренировочная выборка}\\
		\hline
		0 & 1.00 & 0.97 & 0.99 &
		\multirow{2}{*}{0.98} &   
		\multirow{2}{*}{0.98} &  
		469239 \\                    
		\cline{1-4} \cline{7-7}
		1 & 0.95 & 1.00 & 0.97 &  
		&      & 280761 \\       
		\hline
		\multicolumn{7}{|c|}{Тестовая выборка} \\
		\hline
		0 & 1.00 & 0.97 & 0.98 &
		\multirow{2}{*}{0.98} &
		\multirow{2}{*}{0.98} &
		156325 \\
		\cline{1-4} \cline{7-7}
		1 & 0.95 & 1.00 & 0.97 & & & 93676 \\
		\hline
	\end{longtable}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{center}

Метрики $accuracy$ и $ROC-AUC$ демонстрируют одинаковую высокую точность, что также относит нейронные сети к наиболее предпочтительным алгоритмам для прогнозирования дефолта заемщиков (см. Рисунок \ref{ROC_AUC_nn_train_test}).

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{./ch2/graphics/ROC_AUC_NN_train_test.png}
	\caption{Метрика ROC--AUC на тренировочных и тестовых данных алгоритма Neural Network}
	\label{ROC_AUC_nn_train_test}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}

Матрицы ошибок на тренировочных и тестовых данных (см. Рисунок  \ref{matrix_nn_test_train}) показывают, что доли ошибочно отнесенных недефолтных клиентов к дефолтным относительно одинаковы и составляют около 3\%. Также соотношение ошибочно предсказанных дефолтных клиентов к недефолтным на обеих выборках одинакова и приблизительно составляет 0.3\%. Такое равное соотношение показывает, что нейронные сети являются одним из лучших моделей для прогнозов.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{./ch2/graphics/matrix_nn_test_train.png}
	\caption{Матрица ошибок на тренировочных и тестовых данных алгоритма Neural Network}
	\label{matrix_nn_test_train}
	\vspace{10pt}
	\begin{minipage}{\textwidth}
		\fontsize{9}{11}\selectfont
		\justifying
		Источник: составлено автором на основе: Соревнование на данных кредитных историй [Электронный ресурс] / Open Data Science. -- URL: \url{https://ods.ai/competitions/dl-fintech-bki} (дата обращения: 25.11.2025).
	\end{minipage}
\end{figure}